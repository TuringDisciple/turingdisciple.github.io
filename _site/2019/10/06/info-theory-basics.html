<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Information theory basics</title>
  <meta name="description" content="Introduction Recently I have had the opportunity to learn a bit about information theory. Here are my crash course notes on the basic idea behind information...">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="shortcut icon" type="image/png" href="/favicon.png">
  <link rel="canonical" href="http://localhost:4000/2019/10/06/info-theory-basics.html">
  <link rel="alternate" type="application/rss+xml" title="nashpotato" href="/feed.xml">
  
  
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

</head>
<body><header class="site-header" role="banner">

  <div class="wrapper">
    
    
    <a class="site-title" href="/">nashpotato</a>
  
    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
          
            
            
            <a class="page-link" href="/about.html">About</a>
            
          
            
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Information theory basics</h1>
    <p class="post-meta">
      <time datetime="2019-10-06T00:00:00+01:00" itemprop="datePublished">
        
        Oct 6, 2019
      </time>
      </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <h1 id="introduction">Introduction</h1>
<p>Recently I have had the opportunity to learn a bit about information theory. Here are my crash course notes on the basic idea behind information theory. To learn more, Google is a great resource and so is the <a href="http://www.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf">original paper</a> written by Shannon in the late 40s which proposed the theory. This is one of the most exciting mathematical concepts especially when it comes to wide reaching applications in computer science.</p>

<p>With information theory we are trying to understand the amount of information that can be communicated across a channel by only measuing the statistics of data travelling along that channel.</p>

<h1 id="shannons-entropy">Shannon’s entropy</h1>
<p>The theory of information starts with an attemp to allow us to quantify the informativeness of information, but not it’s salience or validity.</p>

<p>Shannon’s entropy is a single quantity that measures this idea of informativeness, balancing how useful a pieve of information is with how likely you are to get it.</p>

<p>Let $X$ be random variable for a finite discrete distribution of size $n$, and a probability mass function $p_{X}$ giving probabilities $p_{X}(x_i)$, the entropy is</p>

<script type="math/tex; mode=display">H(X) = - \sum_{x_i \in X} p_X(x_i)\log_2p_X(x_i)</script>

<p>The first thing to note is that this definition works for any sample space. $H(X)$ is always defined for all sample spaces, as all sample spaces have a defined probability for each element. A prpoperty of Shannon’s entropy is that</p>

<script type="math/tex; mode=display">H(X) \geq 0</script>

<p>This follows from $0\geq p_X(x_i) \leq 1$. Furthermore it can be trivially proven that if all events are equally likely then</p>

<script type="math/tex; mode=display">H(X) = \log \#(\mathcal X)</script>

<p>It can be proven also that</p>

<script type="math/tex; mode=display">H(X) \leq \log \# \mathcal(X)</script>

<p>This essentially means that the most informative an experiment can be is when we have no idea before the experiment of what the outcome is, which is essentially when every possibility is equally likely.</p>

<p>Furthermore if $p_X(x_k) = 1$ for some $k$, then $H(X) = 0$. This makes sense in that we have absolute certainty in an outcome meaning no information is gained by viewing the outcome.</p>

<p>The source coding theorem shows that the entropy $H(X)$ is a lower bound on the average length of a message using the most efficient code; it is a limit on the compressibility of the data.</p>

<h1 id="joint-entropy-and-conditional-entropy">Joint entropy and conditional entropy</h1>
<p>The joint entropy is just the entropy pf the joint distribution:</p>

<script type="math/tex; mode=display">H(X, Y) = - \sum_{x, y}p_{X,Y}\log_{2} p_{X, Y}(x, y)</script>

<table>
  <tbody>
    <tr>
      <td>we can intuitively think of the conditional probabilty as the probability of a value multiplied by the conditional of another value when given the initial one i.e $p_(x, y) = p(x</td>
      <td>y)p(y)$.</td>
    </tr>
  </tbody>
</table>

<p>The conditional entropy can then be given as follows</p>

<script type="math/tex; mode=display">H(X|Y=y) = - \sum_x p_{X|Y}(x|y)\log_2 p_{X|Y}(x|y)</script>

<p>This is the entropy of the variable $X$ if we know $Y=y$. The conditional probability is the <strong>average</strong> of this, averaged of all the values of $y$</p>

<script type="math/tex; mode=display">H(X|Y) = - \sum_y p_Y(y)H(X|Y=y) = - \sum_{x, y}p_(X, Y)\log_2 p_{X|Y}(x|y)</script>

<table>
  <tbody>
    <tr>
      <td>If $X$ and $Y$ are independent, then $H(X</td>
      <td>Y) = H(X)$. Conversely if $X$ is determined by $Y$ i.e. $x = f(y)$, then in this case</td>
    </tr>
  </tbody>
</table>

<script type="math/tex; mode=display">H(X|Y) = 0</script>

<table>
  <tbody>
    <tr>
      <td>Intuitvely we can think of $H(X</td>
      <td>Y)$ to be the average amount of information within $X$ given that we know $Y$.</td>
    </tr>
  </tbody>
</table>

<p>There’s also the chain rule of entropy</p>

<script type="math/tex; mode=display">H(X, Y) = H(X) + H(Y|X)</script>

<p>this intuitively makes sense as it describes how the joint information will be the information in $X$ as well as the information left-over in $Y$ when we have $X$.</p>

<h1 id="mutual-information">Mutual information</h1>
<p>The mutual information is the measure of how related two distributions are, it is given by</p>

<script type="math/tex; mode=display">I(X, Y) = H(X) + H(Y) - H(X, Y)</script>

<p>Thus it is the amount of information in X and Y considered separately, minus the amount of information in them considered together.</p>

<table>
  <tbody>
    <tr>
      <td>If the two distributions are independent $I(X, Y) = 0$, conversely if $Y$ is determined by $X$, then $H(Y</td>
      <td>X) = 0$ and $H(X,Y) = H(X)$ and $I(X, Y) = H(Y)$.</td>
    </tr>
  </tbody>
</table>

  </div>

  
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

</article>


      </div>
    </main><footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">nashpotato</h2>

    <div class="footer-col-wrapper">
      

      <div class="footer-col footer-col-1">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/nashpotato"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">nashpotato</span></a>

          </li>
          
          
          <li>
                <a href="https://twitter.com/nashepotato"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">nashepotato</span></a>

          </li>
          
           
          <li><a class="u-email" href="mailto:mncubenashe@gmail.com">mncubenashe@gmail.com</a></li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p></p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
